# E2E-003: Execute Full Playwright E2E Test Suite Against Production

<!-- METADATA (for validation) -->
<!-- TASK_ID: E2E-003 -->
<!-- TASK_TITLE: Execute Full Playwright E2E Test Suite Against Production -->
<!-- PROMPT_VERSION: 1.0 -->
<!-- LAST_VALIDATED: 2026-01-16 -->

**Repository:** https://github.com/EvanTenenbaum/TERP  
**Task ID:** E2E-003  
**Estimated Time:** 16h  
**Module:** `tests-e2e/`, `playwright.config.ts`

‚ö†Ô∏è **SECURITY WARNING**

- NEVER include real secrets in this prompt
- Use placeholders like: `YOUR_API_KEY_HERE`
- Secrets belong in `.env` file only

---

## üìã Table of Contents

1. [Context](#context)
2. [Phase 1: Pre-Flight Check](#phase-1-pre-flight-check)
3. [Phase 2: Session Startup](#phase-2-session-startup)
4. [Phase 3: Development](#phase-3-development)
5. [Phase 4: Completion](#phase-4-completion)
6. [Quick Reference](#quick-reference)
7. [Troubleshooting](#troubleshooting)

---

## üéØ Context

**Background:**
The TERP repository contains 338 E2E tests across multiple categories:

- Core tests (auth, crud, navigation): ~92 tests
- Critical Paths (workflows): ~178 tests
- Mega Tests (perf, security, a11y): ~40 tests
- AI-Generated: ~28 tests

Currently, only a subset of tests have been run against production. A full test execution is needed to identify all failures and establish a baseline.

**Goal:**
Execute all 338 E2E tests against production, document results, identify failures, and create a comprehensive test report.

**Success Criteria:**

- All 338 tests executed against production
- Comprehensive test report generated
- All failures documented with root cause analysis
- Baseline pass rate established
- CI pipeline updated to run E2E tests

**Dependencies:**

- E2E-001 (Auth credentials) should be completed first
- E2E-002 (Orders selectors) should be completed first

---

## Implementation Guide

### Step 1: Prerequisites

Ensure E2E-001 and E2E-002 are completed:

```bash
# Verify auth works
PLAYWRIGHT_BASE_URL=https://terp-app-b9s35.ondigitalocean.app \
pnpm exec playwright test tests-e2e/auth.spec.ts

# Verify orders selectors work
PLAYWRIGHT_BASE_URL=https://terp-app-b9s35.ondigitalocean.app \
pnpm exec playwright test tests-e2e/orders-crud.spec.ts
```

### Step 2: Configure Production Test Environment

```bash
# Set environment variables
export PLAYWRIGHT_BASE_URL=https://terp-app-b9s35.ondigitalocean.app
export SKIP_E2E_SETUP=true
export MEGA_QA_CLOUD=true
export QA_AUTH_ENABLED=true
```

### Step 3: Execute Full Test Suite

Run tests in batches to avoid timeouts:

```bash
# Batch 1: Core tests
pnpm exec playwright test tests-e2e/auth.spec.ts \
  tests-e2e/navigation-ui.spec.ts \
  tests-e2e/clients-crud.spec.ts \
  tests-e2e/orders-crud.spec.ts \
  tests-e2e/inventory-crud.spec.ts \
  --project=chromium --reporter=json --output=test-results/batch1.json

# Batch 2: Critical paths
pnpm exec playwright test tests-e2e/critical-paths/ \
  --project=chromium --reporter=json --output=test-results/batch2.json

# Batch 3: Mega tests
pnpm exec playwright test tests-e2e/mega/ \
  --project=chromium --reporter=json --output=test-results/batch3.json

# Batch 4: AI-generated and patterns
pnpm exec playwright test tests-e2e/ai-generated/ tests-e2e/patterns/ \
  --project=chromium --reporter=json --output=test-results/batch4.json
```

### Step 4: Generate Comprehensive Report

Create report at `qa-results/E2E_FULL_SUITE_REPORT.md`:

```markdown
# E2E Full Suite Test Report

## Summary

- **Total Tests:** 338
- **Passed:** X
- **Failed:** Y
- **Skipped:** Z
- **Pass Rate:** X%

## Failures by Category

| Category   | Total | Passed | Failed | Pass Rate |
| ---------- | ----- | ------ | ------ | --------- |
| Auth       | 10    | ?      | ?      | ?%        |
| Navigation | 12    | ?      | ?      | ?%        |

| ...

## Failure Details

### [Test Name]

- **File:** path/to/test.spec.ts
- **Error:** Error message
- **Root Cause:** Analysis
- **Fix Required:** Description
```

### Step 5: Update CI Pipeline

Add E2E test job to GitHub Actions:

**File:** `.github/workflows/e2e-tests.yml`

```yaml
name: E2E Tests
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: "0 6 * * *" # Daily at 6 AM

jobs:
  e2e:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v2
      - uses: actions/setup-node@v4
      - run: pnpm install
      - run: pnpm exec playwright install chromium
      - run: pnpm exec playwright test --project=chromium
        env:
          PLAYWRIGHT_BASE_URL: ${{ secrets.PROD_URL }}
          SKIP_E2E_SETUP: true
```

---

## Phase 1: Pre-Flight Check

### Step 1.1: Verify Prerequisites

```bash
# Check E2E-001 and E2E-002 are complete
grep "E2E-001" docs/roadmaps/MASTER_ROADMAP.md
grep "E2E-002" docs/roadmaps/MASTER_ROADMAP.md
```

### Step 1.2: Register Your Session

Create session file: `docs/sessions/active/Session-[DATE]-[NUMBER].md`

---

## Phase 2: Session Startup

### Step 2.1: Create Feature Branch

```bash
git checkout main
git pull origin main
git checkout -b E2E-003-full-suite-execution
```

---

## Phase 3: Development

Follow the Implementation Guide above.

---

## Phase 4: Completion

### Step 4.1: Verify All Deliverables

- [ ] All 338 tests executed
- [ ] Comprehensive report generated
- [ ] All failures documented
- [ ] CI pipeline updated
- [ ] Baseline pass rate established

### Step 4.2: Push and Create PR

```bash
git add .
git commit -m "feat(e2e): Execute full E2E suite and establish baseline"
git push origin E2E-003-full-suite-execution
```

---

## ‚ö° Quick Reference

| Category       | Test Count | Files                       |
| -------------- | ---------- | --------------------------- |
| Core           | ~92        | `tests-e2e/*.spec.ts`       |
| Critical Paths | ~178       | `tests-e2e/critical-paths/` |
| Mega           | ~40        | `tests-e2e/mega/`           |
| AI-Generated   | ~28        | `tests-e2e/ai-generated/`   |

---

## üÜò Troubleshooting

**Issue:** Tests timeout
**Solution:** Increase timeout in playwright.config.ts or run in smaller batches

**Issue:** Too many failures to analyze
**Solution:** Focus on critical-paths first, then expand

**Issue:** Flaky tests
**Solution:** Mark as flaky with `test.describe.configure({ retries: 2 })`
